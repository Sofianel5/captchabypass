{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def load_data(data_dir, flatten=False):\n",
    "    train_dir = os.path.join(data_dir, 'train')\n",
    "    test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "    meta_info = os.path.join(data_dir, 'meta.json')\n",
    "    with open(meta_info, 'r') as f:\n",
    "        meta = json.load(f)\n",
    "\n",
    "    train_images, train_labels = _read_images_and_labels(train_dir, flatten=flatten, **meta)\n",
    "    test_images, test_labels = _read_images_and_labels(test_dir, flatten=flatten, **meta)\n",
    "\n",
    "    return (\n",
    "        meta,\n",
    "        DataSet(train_images, train_labels),\n",
    "        DataSet(test_images, test_labels),\n",
    "    )\n",
    "\n",
    "\n",
    "def _read_images_and_labels(dir_name, flatten, ext='.png', **meta):\n",
    "    images = []\n",
    "    labels = []\n",
    "    i = 0\n",
    "    l = os.listdir(dir_name)[:int(len(os.listdir(dir_name))/1.5)]\n",
    "    for fn in l:\n",
    "        if fn.endswith(ext):\n",
    "            fd = os.path.join(dir_name, fn)\n",
    "            images.append(_read_image(fd, flatten=flatten, **meta))\n",
    "            labels.append(_read_label(fd, **meta))\n",
    "            i += 1\n",
    "        print('\\r', len(images), end=\"\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "def _read_image(filename, flatten, width, height, **extra_meta):\n",
    "    im = Image.open(filename).convert('L').resize((width, height), Image.ANTIALIAS)\n",
    "\n",
    "    data = np.asarray(im)\n",
    "    if flatten:\n",
    "        return data.reshape(width * height)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def _read_label(filename, label_choices, **extra_meta):\n",
    "    basename = os.path.basename(filename)\n",
    "    labels = basename.split('_')[0]\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for c in labels:\n",
    "        idx = label_choices.index(c)\n",
    "        tmp = [0] * len(label_choices)\n",
    "        tmp[idx] = 1\n",
    "        data.extend(tmp)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "class DataSet(object):\n",
    "    \"\"\"Provide `next_batch` method, which returns the next `batch_size` examples from this data set.\"\"\"\n",
    "\n",
    "    def __init__(self, images, labels):\n",
    "        assert images.shape[0] == labels.shape[0], (\n",
    "            'images.shape: %s labels.shape: %s' % (images.shape, labels.shape))\n",
    "        self._num_examples = images.shape[0]\n",
    "\n",
    "        self._images = images\n",
    "        self._labels = labels\n",
    "\n",
    "        self._epochs_completed = 0\n",
    "        self._index_in_epoch = 0\n",
    "\n",
    "    @property\n",
    "    def images(self):\n",
    "        return self._images\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "\n",
    "    @property\n",
    "    def epochs_completed(self):\n",
    "        return self._epochs_completed\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "\n",
    "        assert batch_size <= self._num_examples\n",
    "\n",
    "        if self._index_in_epoch + batch_size > self._num_examples:\n",
    "            # Finished epoch\n",
    "            self._epochs_completed += 1\n",
    "            self._index_in_epoch = 0\n",
    "\n",
    "        if self._index_in_epoch == 0:\n",
    "            # Shuffle the data\n",
    "            perm = np.arange(self._num_examples)\n",
    "            np.random.shuffle(perm)\n",
    "            self._images = self._images[perm]\n",
    "            self._labels = self._labels[perm]\n",
    "\n",
    "        # read next batch\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += batch_size\n",
    "        return self._images[start:self._index_in_epoch], self._labels[start:self._index_in_epoch]\n",
    "\n",
    "\n",
    "def display_debug_info(meta, train_data, test_data):\n",
    "    print('%s Meta Info %s' % ('=' * 10, '=' * 10))\n",
    "    for k, v in meta.items():\n",
    "        print('%s: %s' % (k, v))\n",
    "    print('=' * 30)\n",
    "\n",
    "    print('train images: %s, labels: %s' % (train_data.images.shape, train_data.labels.shape))\n",
    "\n",
    "    print('test images: %s, labels: %s' % (test_data.images.shape, test_data.labels.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "starting to load\n",
      " 2393400129697902632719632739736468048419660837761870367051567760970574271094073756074288274826177143587093091306596926010069331033708117058611814861262729129773413565403972907793325data loaded\n",
      "train images: 1435200. test images: 239340\n",
      "label_size: 26, image_size: 12000\n",
      "WARNING:tensorflow:From <ipython-input-2-269608d341ee>:94: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0418 06:35:49.950738 140008536733504 deprecation.py:506] From <ipython-input-2-269608d341ee>:94: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-269608d341ee>:112: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0418 06:35:49.969437 140008536733504 deprecation.py:323] From <ipython-input-2-269608d341ee>:112: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy = 4.00%, testing accuracy = 4.37%\n",
      "step 100, training accuracy = 5.00%, testing accuracy = 3.69%\n",
      "step 200, training accuracy = 3.50%, testing accuracy = 4.29%\n",
      "step 300, training accuracy = 2.00%, testing accuracy = 3.89%\n",
      "step 400, training accuracy = 1.50%, testing accuracy = 3.86%\n",
      "step 500, training accuracy = 2.50%, testing accuracy = 4.15%\n",
      "step 600, training accuracy = 4.00%, testing accuracy = 4.55%\n",
      "step 700, training accuracy = 7.00%, testing accuracy = 4.26%\n",
      "step 800, training accuracy = 6.00%, testing accuracy = 4.25%\n",
      "step 900, training accuracy = 5.00%, testing accuracy = 4.25%\n",
      "step 1000, training accuracy = 4.00%, testing accuracy = 3.82%\n",
      "step 1100, training accuracy = 3.00%, testing accuracy = 3.84%\n",
      "step 1200, training accuracy = 6.00%, testing accuracy = 4.19%\n",
      "step 1300, training accuracy = 5.00%, testing accuracy = 4.05%\n",
      "step 1400, training accuracy = 4.00%, testing accuracy = 3.84%\n",
      "step 1500, training accuracy = 8.00%, testing accuracy = 3.96%\n",
      "step 1600, training accuracy = 5.00%, testing accuracy = 4.10%\n",
      "step 1700, training accuracy = 4.50%, testing accuracy = 4.16%\n",
      "step 1800, training accuracy = 5.00%, testing accuracy = 4.54%\n",
      "step 1900, training accuracy = 5.00%, testing accuracy = 3.97%\n",
      "step 2000, training accuracy = 5.50%, testing accuracy = 4.00%\n",
      "step 2100, training accuracy = 6.00%, testing accuracy = 3.95%\n",
      "step 2200, training accuracy = 3.50%, testing accuracy = 4.13%\n",
      "step 2300, training accuracy = 4.00%, testing accuracy = 4.06%\n",
      "step 2400, training accuracy = 4.50%, testing accuracy = 4.01%\n",
      "step 2500, training accuracy = 4.50%, testing accuracy = 3.93%\n",
      "step 2600, training accuracy = 6.50%, testing accuracy = 4.22%\n",
      "step 2700, training accuracy = 4.00%, testing accuracy = 4.16%\n",
      "step 2800, training accuracy = 3.50%, testing accuracy = 4.04%\n",
      "step 2900, training accuracy = 3.50%, testing accuracy = 3.96%\n",
      "step 3000, training accuracy = 7.00%, testing accuracy = 4.36%\n",
      "step 3100, training accuracy = 5.50%, testing accuracy = 4.13%\n",
      "step 3200, training accuracy = 2.00%, testing accuracy = 4.01%\n",
      "step 3300, training accuracy = 5.00%, testing accuracy = 3.42%\n",
      "step 3400, training accuracy = 4.50%, testing accuracy = 3.82%\n",
      "step 3500, training accuracy = 4.00%, testing accuracy = 4.00%\n",
      "step 3600, training accuracy = 4.00%, testing accuracy = 3.97%\n",
      "step 3700, training accuracy = 4.50%, testing accuracy = 4.11%\n",
      "step 3800, training accuracy = 3.50%, testing accuracy = 3.77%\n",
      "step 3900, training accuracy = 5.50%, testing accuracy = 3.67%\n",
      "step 4000, training accuracy = 5.50%, testing accuracy = 3.90%\n",
      "step 4100, training accuracy = 3.00%, testing accuracy = 4.17%\n",
      "step 4200, training accuracy = 3.00%, testing accuracy = 4.14%\n",
      "step 4300, training accuracy = 4.50%, testing accuracy = 3.82%\n",
      "step 4400, training accuracy = 4.50%, testing accuracy = 4.15%\n",
      "step 4500, training accuracy = 4.00%, testing accuracy = 4.00%\n",
      "step 4600, training accuracy = 2.50%, testing accuracy = 3.97%\n",
      "step 4700, training accuracy = 4.50%, testing accuracy = 3.53%\n",
      "step 4800, training accuracy = 2.50%, testing accuracy = 3.95%\n",
      "step 4900, training accuracy = 3.50%, testing accuracy = 4.15%\n",
      "step 5000, training accuracy = 1.50%, testing accuracy = 3.76%\n",
      "step 5100, training accuracy = 3.00%, testing accuracy = 3.60%\n",
      "step 5200, training accuracy = 4.50%, testing accuracy = 3.86%\n",
      "step 5300, training accuracy = 5.00%, testing accuracy = 3.88%\n",
      "step 5400, training accuracy = 4.00%, testing accuracy = 3.75%\n",
      "step 5500, training accuracy = 4.50%, testing accuracy = 4.21%\n",
      "step 5600, training accuracy = 6.00%, testing accuracy = 3.95%\n",
      "step 5700, training accuracy = 4.00%, testing accuracy = 3.31%\n",
      "step 5800, training accuracy = 4.00%, testing accuracy = 3.65%\n",
      "step 5900, training accuracy = 2.50%, testing accuracy = 3.65%\n",
      "step 6000, training accuracy = 2.00%, testing accuracy = 3.73%\n",
      "step 6100, training accuracy = 4.50%, testing accuracy = 3.84%\n",
      "step 6200, training accuracy = 4.00%, testing accuracy = 4.05%\n",
      "step 6300, training accuracy = 4.00%, testing accuracy = 3.38%\n",
      "step 6400, training accuracy = 5.00%, testing accuracy = 3.88%\n",
      "step 6500, training accuracy = 2.50%, testing accuracy = 3.49%\n",
      "step 6600, training accuracy = 4.50%, testing accuracy = 4.05%\n",
      "step 6700, training accuracy = 5.00%, testing accuracy = 3.91%\n",
      "step 6800, training accuracy = 2.50%, testing accuracy = 4.16%\n",
      "step 6900, training accuracy = 3.50%, testing accuracy = 4.22%\n",
      "step 7000, training accuracy = 6.00%, testing accuracy = 3.74%\n",
      "step 7100, training accuracy = 3.50%, testing accuracy = 3.82%\n",
      "step 7200, training accuracy = 4.00%, testing accuracy = 3.45%\n",
      "step 7300, training accuracy = 6.00%, testing accuracy = 3.71%\n",
      "step 7400, training accuracy = 4.00%, testing accuracy = 4.25%\n",
      "step 7500, training accuracy = 3.50%, testing accuracy = 4.11%\n",
      "step 7600, training accuracy = 5.50%, testing accuracy = 3.91%\n",
      "step 7700, training accuracy = 3.00%, testing accuracy = 3.56%\n",
      "step 7800, training accuracy = 3.50%, testing accuracy = 3.38%\n",
      "step 7900, training accuracy = 1.50%, testing accuracy = 3.56%\n",
      "step 8000, training accuracy = 3.00%, testing accuracy = 3.90%\n",
      "step 8100, training accuracy = 2.50%, testing accuracy = 3.67%\n",
      "step 8200, training accuracy = 2.50%, testing accuracy = 4.04%\n",
      "step 8300, training accuracy = 3.00%, testing accuracy = 3.97%\n",
      "step 8400, training accuracy = 2.50%, testing accuracy = 3.79%\n",
      "step 8500, training accuracy = 5.50%, testing accuracy = 3.85%\n",
      "step 8600, training accuracy = 1.50%, testing accuracy = 3.59%\n",
      "step 8700, training accuracy = 4.00%, testing accuracy = 3.58%\n",
      "step 8800, training accuracy = 4.50%, testing accuracy = 3.82%\n",
      "step 8900, training accuracy = 3.50%, testing accuracy = 4.08%\n",
      "step 9000, training accuracy = 5.00%, testing accuracy = 3.59%\n",
      "step 9100, training accuracy = 5.50%, testing accuracy = 3.71%\n",
      "step 9200, training accuracy = 2.50%, testing accuracy = 3.73%\n",
      "step 9300, training accuracy = 3.50%, testing accuracy = 3.60%\n",
      "step 9400, training accuracy = 5.50%, testing accuracy = 3.88%\n",
      "step 9500, training accuracy = 4.00%, testing accuracy = 3.62%\n",
      "step 9600, training accuracy = 5.00%, testing accuracy = 4.05%\n",
      "step 9700, training accuracy = 6.50%, testing accuracy = 3.61%\n",
      "step 9800, training accuracy = 4.00%, testing accuracy = 3.97%\n",
      "step 9900, training accuracy = 2.50%, testing accuracy = 3.71%\n",
      "testing accuracy = 4.16%\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "MAX_STEPS = 10000\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "LOG_DIR = 'log/cnn1-run-%s' % datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "\n",
    "def variable_summaries(var):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        # with tf.name_scope('stddev'):\n",
    "        #    stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        # tf.summary.scalar('stddev', stddev)\n",
    "        # tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        # tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        # tf.summary.histogram('histogram', var)\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    # load data\n",
    "    print(\"starting to load\")\n",
    "    meta, train_data, test_data = load_data(FLAGS.data_dir, flatten=False)\n",
    "    print('data loaded')\n",
    "    print('train images: %s. test images: %s' % (train_data.images.shape[0], test_data.images.shape[0]))\n",
    "\n",
    "    LABEL_SIZE = meta['label_size']\n",
    "    NUM_PER_IMAGE = meta['num_per_image']\n",
    "    IMAGE_HEIGHT = meta['height']\n",
    "    IMAGE_WIDTH = meta['width']\n",
    "    IMAGE_SIZE = IMAGE_WIDTH * IMAGE_HEIGHT\n",
    "    print('label_size: %s, image_size: %s' % (LABEL_SIZE, IMAGE_SIZE))\n",
    "\n",
    "    # variable in the graph for input data\n",
    "    with tf.name_scope('input'):\n",
    "        x = tf.placeholder(tf.float32, [None, IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "        y_ = tf.placeholder(tf.float32, [None, NUM_PER_IMAGE * LABEL_SIZE])\n",
    "\n",
    "        # must be 4-D with shape `[batch_size, height, width, channels]`\n",
    "        x_image = tf.reshape(x, [-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1])\n",
    "        tf.summary.image('input', x_image, max_outputs=LABEL_SIZE)\n",
    "\n",
    "    # define the model\n",
    "    with tf.name_scope('convolution-layer-1'):\n",
    "        W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "        b_conv1 = bias_variable([32])\n",
    "\n",
    "        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "    with tf.name_scope('convolution-layer-2'):\n",
    "        W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "        b_conv2 = bias_variable([64])\n",
    "\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "    with tf.name_scope('densely-connected'):\n",
    "        W_fc1 = weight_variable([IMAGE_WIDTH * IMAGE_HEIGHT * 4, 1024])\n",
    "        b_fc1 = bias_variable([1024])\n",
    "\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, IMAGE_WIDTH*IMAGE_HEIGHT*4])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "    with tf.name_scope('dropout'):\n",
    "        # To reduce overfitting, we will apply dropout before the readout layer\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "    with tf.name_scope('readout'):\n",
    "        W_fc2 = weight_variable([1024, NUM_PER_IMAGE * LABEL_SIZE])\n",
    "        b_fc2 = bias_variable([NUM_PER_IMAGE * LABEL_SIZE])\n",
    "\n",
    "        y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "    with tf.name_scope('reshape'):\n",
    "        y_expect_reshaped = tf.reshape(y_, [-1, NUM_PER_IMAGE, LABEL_SIZE])\n",
    "        y_got_reshaped = tf.reshape(y_conv, [-1, NUM_PER_IMAGE, LABEL_SIZE])\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    # Returns:\n",
    "    # A 1-D `Tensor` of length `batch_size`\n",
    "    # of the same type as `logits` with the softmax cross entropy loss.\n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(labels=y_expect_reshaped, logits=y_got_reshaped))\n",
    "        train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "        variable_summaries(cross_entropy)\n",
    "\n",
    "    # forword prop\n",
    "    with tf.name_scope('forword-prop'):\n",
    "        predict = tf.argmax(y_got_reshaped, axis=2)\n",
    "        expect = tf.argmax(y_expect_reshaped, axis=2)\n",
    "\n",
    "    # evaluate accuracy\n",
    "    with tf.name_scope('evaluate_accuracy'):\n",
    "        correct_prediction = tf.equal(predict, expect)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        variable_summaries(accuracy)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter(LOG_DIR + '/train', sess.graph)\n",
    "        test_writer = tf.summary.FileWriter(LOG_DIR + '/test', sess.graph)\n",
    "\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        # Train\n",
    "        for i in range(MAX_STEPS):\n",
    "            batch_xs, batch_ys = train_data.next_batch(BATCH_SIZE)\n",
    "\n",
    "            step_summary, _ = sess.run([merged, train_step], feed_dict={x: batch_xs, y_: batch_ys, keep_prob: 1.0})\n",
    "            train_writer.add_summary(step_summary, i)\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                # Test trained model\n",
    "                valid_summary, train_accuracy = sess.run([merged, accuracy], feed_dict={x: batch_xs, y_: batch_ys, keep_prob: 1.0})\n",
    "                train_writer.add_summary(valid_summary, i)\n",
    "\n",
    "                # final check after looping\n",
    "                test_x, test_y = test_data.next_batch(2000)\n",
    "                test_summary, test_accuracy = sess.run([merged, accuracy], feed_dict={x: test_x, y_: test_y, keep_prob: 1.0})\n",
    "                test_writer.add_summary(test_summary, i)\n",
    "\n",
    "                print('step %s, training accuracy = %.2f%%, testing accuracy = %.2f%%' % (i, train_accuracy * 100, test_accuracy * 100))\n",
    "\n",
    "        train_writer.close()\n",
    "        test_writer.close()\n",
    "\n",
    "        # final check after looping\n",
    "        test_x, test_y = test_data.next_batch(2000)\n",
    "        test_accuracy = accuracy.eval(feed_dict={x: test_x, y_: test_y, keep_prob: 1.0})\n",
    "        print('testing accuracy = %.2f%%' % (test_accuracy * 100, ))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"called\")\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data_dir', type=str, default='images/char-4-epoch-6/',\n",
    "                        help='Directory for storing input data')\n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "    tf.compat.v1.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
